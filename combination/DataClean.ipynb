{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 8)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import re\n",
    "\n",
    "PATH = '../../data/'\n",
    "\n",
    "train = pd.read_csv(PATH + 'train.csv')\n",
    "test = pd.read_csv(PATH + 'test.csv')\n",
    "\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "APO = {\n",
    "    \"aren't\" : \"are not\",\n",
    "    \"can't\" : \"cannot\",\n",
    "    \"couldn't\" : \"could not\",\n",
    "    \"didn't\" : \"did not\",\n",
    "    \"doesn't\" : \"does not\",\n",
    "    \"don't\" : \"do not\",\n",
    "    \"hadn't\" : \"had not\",\n",
    "    \"hasn't\" : \"has not\",\n",
    "    \"haven't\" : \"have not\",\n",
    "    \"he'd\" : \"he would\",\n",
    "    \"he'll\" : \"he will\",\n",
    "    \"he's\" : \"he is\",\n",
    "    \"i'd\" : \"I would\",\n",
    "    \"i'd\" : \"I had\",\n",
    "    \"i'll\" : \"I will\",\n",
    "    \"i'm\" : \"I am\",\n",
    "    \"isn't\" : \"is not\",\n",
    "    \"it's\" : \"it is\",\n",
    "    \"it'll\":\"it will\",\n",
    "    \"i've\" : \"I have\",\n",
    "    \"let's\" : \"let us\",\n",
    "    \"mightn't\" : \"might not\",\n",
    "    \"mustn't\" : \"must not\",\n",
    "    \"shan't\" : \"shall not\",\n",
    "    \"she'd\" : \"she would\",\n",
    "    \"she'll\" : \"she will\",\n",
    "    \"she's\" : \"she is\",\n",
    "    \"shouldn't\" : \"should not\",\n",
    "    \"that's\" : \"that is\",\n",
    "    \"there's\" : \"there is\",\n",
    "    \"they'd\" : \"they would\",\n",
    "    \"they'll\" : \"they will\",\n",
    "    \"they're\" : \"they are\",\n",
    "    \"they've\" : \"they have\",\n",
    "    \"we'd\" : \"we would\",\n",
    "    \"we're\" : \"we are\",\n",
    "    \"weren't\" : \"were not\",\n",
    "    \"we've\" : \"we have\",\n",
    "    \"what'll\" : \"what will\",\n",
    "    \"what're\" : \"what are\",\n",
    "    \"what's\" : \"what is\",\n",
    "    \"what've\" : \"what have\",\n",
    "    \"where's\" : \"where is\",\n",
    "    \"who'd\" : \"who would\",\n",
    "    \"who'll\" : \"who will\",\n",
    "    \"who're\" : \"who are\",\n",
    "    \"who's\" : \"who is\",\n",
    "    \"who've\" : \"who have\",\n",
    "    \"won't\" : \"will not\",\n",
    "    \"wouldn't\" : \"would not\",\n",
    "    \"you'd\" : \"you would\",\n",
    "    \"you'll\" : \"you will\",\n",
    "    \"you're\" : \"you are\",\n",
    "    \"you've\" : \"you have\",\n",
    "    \"'re\": \" are\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'll\":\" will\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"tryin'\":\"trying\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "na\n"
     ]
    }
   ],
   "source": [
    "# get stopwords\n",
    "stopword = set(stopwords.words(\"english\"))\n",
    "lem = WordNetLemmatizer()\n",
    "tok = TweetTokenizer()\n",
    "\n",
    "def clean(comment):\n",
    "    comment = comment.lower()\n",
    "    comment = re.sub(r'\\n', ' ', comment)\n",
    "    comment=re.sub('\\d{1,3}.\\d{1,3}.\\d{1,3}.\\d{1,3}', '',comment) # remove leaky elements like ip,user\n",
    "    comment=re.sub('\\[\\[.*\\]', '',comment)    #removing usernames\n",
    "    comment = re.sub(' +', ' ', comment)\n",
    "    text = tok.tokenize(comment)\n",
    "    text = [APO[word] if word in APO else word for word in text]\n",
    "#     text = [w for w in text if not w in stopword]\n",
    "    text = [lem.lemmatize(word, 'v') for word in text]\n",
    "    text = [lem.lemmatize(word, 'n') for word in text]\n",
    "    text = ' '.join(text)\n",
    "    if text == '': text = 'na'\n",
    "    return text\n",
    "\n",
    "train['comment_text'].fillna('na', inplace=True)\n",
    "train['comment_text_cleaned'] = train['comment_text'].apply(lambda x :clean(x))\n",
    "\n",
    "test['comment_text'].fillna('na', inplace=True)\n",
    "test['comment_text_cleaned'] = test['comment_text'].apply(lambda x :clean(x))\n",
    "\n",
    "print(train.loc[15217, 'comment_text_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "train.to_csv(PATH + 'cleaned_train.csv')\n",
    "test.to_csv(PATH + 'cleaned_test.csv')\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
