{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/nblogreg/train_nblogreg.csv\n",
      "../../data/nblogreg/nblogreg.csv\n",
      "../../data/nbnn/train_nbnn.csv\n",
      "../../data/nbnn/nbnn.csv\n",
      "../../data/cnn/train_cnn.csv\n",
      "../../data/cnn/cnn.csv\n",
      "../../data/lstm/train_lstm.csv\n",
      "../../data/lstm/lstm.csv\n",
      "other features\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model = ['nblogreg', 'nbnn', 'cnn', 'lstm']\n",
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "PATH = '../../data/'\n",
    "\n",
    "train_file = PATH + model[0] + '/train_' + model[0] + '.csv'\n",
    "test_file = PATH + model[0] + '/' + model[0] + '.csv'\n",
    "print(train_file)\n",
    "print(test_file)\n",
    "\n",
    "train = pd.read_csv(train_file)[label_cols]\n",
    "test = pd.read_csv(test_file)[label_cols]\n",
    "\n",
    "for i in range(1, len(model)):\n",
    "    train_file = PATH + model[i] + '/train_' + model[i] + '.csv'\n",
    "    test_file = PATH + model[i] + '/' + model[i] + '.csv'\n",
    "    print(train_file)\n",
    "    print(test_file)\n",
    "\n",
    "    train = pd.concat([train, pd.read_csv(train_file)[label_cols]], axis=1)\n",
    "    test = pd.concat([test, pd.read_csv(test_file)[label_cols]], axis=1)    \n",
    "\n",
    "other_feature_cols = ['word_count', 'unique_word_count', 'consecutive_question_marks',\\\n",
    "                      'consecutive_exclamation_marks', 'uppercase_letters', 'ellipsis',\\\n",
    "                      'period', 'parentheses_paird', 'cleaned_word_count', 'cleaned_unique_word_count',\\\n",
    "                      'cleaned_consecutive_question_marks', 'cleaned_consecutive_exclamation_marks',\\\n",
    "                      'cleaned_uppercase_letters', 'cleaned_ellipsis', 'cleaned_period', 'cleaned_parentheses_pair']\n",
    "\n",
    "print('other features')\n",
    "train = pd.concat([train, pd.read_csv(PATH + 'cleaned_train.csv')[other_feature_cols]], axis=1)\n",
    "test = pd.concat([test, pd.read_csv(PATH + 'cleaned_test.csv')[other_feature_cols]], axis=1)\n",
    "\n",
    "y = pd.read_csv(PATH + 'train.csv')[label_cols]\n",
    "\n",
    "features = label_cols.extend(other_feature_cols)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit toxic\n",
      "0:\tlearn: 0.6905564\ttest: 0.6905501\tbest: 0.6905501 (0)\ttotal: 555ms\tremaining: 1.11s\n",
      "1:\tlearn: 0.6877716\ttest: 0.6877597\tbest: 0.6877597 (1)\ttotal: 774ms\tremaining: 387ms\n",
      "2:\tlearn: 0.6845809\ttest: 0.6845667\tbest: 0.6845667 (2)\ttotal: 1.41s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6845667484\n",
      "bestIteration = 2\n",
      "\n",
      "Shrink model to first 3 iterations.\n",
      "[7.2041712581584205, 0.0, 1.6064414929271509, 1.5692448305176723, 0.0, 1.4884035517146896, 13.200896342822722, 0.0, 0.0, 0.0, 2.288400856052182, 0.0, 1.175525845849319, 0.0, 0.0, 0.0, 7.240396870929578, 0.0, 11.501658595388621, 20.633581076141883, 0.0, 0.0, 0.0, 29.500843520457114, 0.18572317448344644, 0.0, 0.0, 0.0, 0.0, 0.025967591304285418, 1.3668354048082323, 0.0, 0.40967103733661003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6022385511080937]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6b36bb924be9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                                   loss_function='Logloss')\n\u001b[1;32m     19\u001b[0m     \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_best_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mprint_feature_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# TODO: should ues 1 or 0?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-6b36bb924be9>\u001b[0m in \u001b[0;36mprint_feature_importance\u001b[0;34m(x, feature, models)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mwhich_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mwhich_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhich_model\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwhich_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "def print_feature_importance(x, features, models):\n",
    "    dict = {}\n",
    "    print(x)\n",
    "    for i in range(len(x)):\n",
    "        which_model = models[i // len(features)]\n",
    "        which_feature = features[i % len(features)]\n",
    "        dict[(which_model + ' ' + which_features)] = x[i]\n",
    "    print(dict)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, y, test_size=0.2, random_state=42)\n",
    "\n",
    "out = np.zeros((test.shape[0], len(label_cols)))\n",
    "for i, j in enumerate(label_cols):\n",
    "    print('fit ' + j)\n",
    "    ensemble = CatBoostClassifier(iterations=3,\n",
    "                                  depth=10, \n",
    "                                  learning_rate=0.001, \n",
    "                                  loss_function='Logloss')\n",
    "    ensemble.fit(X_train, y_train[j], use_best_model=True, eval_set=[X_test, y_test[j]])\n",
    "    print_feature_importance(ensemble.get_feature_importance(X_train, y_train[j]), features, model)\n",
    "    out[:, i] = ensemble.predict_proba(test.values)[:, 1] # TODO: should ues 1 or 0?\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv(PATH + 'sample_submission.csv')\n",
    "submission[label_cols] = out\n",
    "submission.to_csv(PATH + 'ensemble/catboost_ensemble.csv', index=False)\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
